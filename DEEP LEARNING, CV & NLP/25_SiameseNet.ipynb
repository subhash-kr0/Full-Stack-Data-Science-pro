{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eNqmnVBzze9"
      },
      "outputs": [],
      "source": [
        "base_network=resnet.ResNet50(weights=\"imagenet\",input_shape=(200,200,3),include_top=False)\n",
        "for layer in base_network.layers[:-3]:\n",
        "  layer.trainable=False\n",
        "pool=GlobalAveragePooling2D()(base_network.output)\n",
        "dense1=Dense(128,activation='tanh')(pool)\n",
        "output=Dense(128)(dense1)\n",
        "embedding=Model(base_network.input,output,name=\"Embedding\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(vects):\n",
        "  x,y=vects\n",
        "  sum_square=K.sum(K.square(x-y),axis=1,keepdims=True)\n",
        "  return K.sqrt((sum_square))"
      ],
      "metadata": {
        "id": "tiYBjFM_1t0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_1=Input(shape=(200,200,3),name=\"input_1\")\n",
        "img_2=Input(shape=(200,200,3),name=\"input_2\")\n",
        "\n",
        "feat_1=embedding(img_1)\n",
        "feat_2=embedding(img_2)\n",
        "\n",
        "distance=Lambda(euclidean_distance)([feat_1,feat_2])\n",
        "\n",
        "model=Model(inputs=[img_1,img_2],outputs=distance)\n"
      ],
      "metadata": {
        "id": "sPRQvhPa16yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def contrastive_loss(y_true,y_pred,margin=1):\n",
        "  squared_distance_similar=K.square(y_pred)\n",
        "  squared_distance_nonsimilar=k.square(K.maximum(margin-y_pred,0))\n",
        "  loss=K.mean(y_true*squared_distance_similar+(1-y_true)*(squared_distance_nonsimilar))"
      ],
      "metadata": {
        "id": "miuO0kgH30jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Lambda, Flatten, Dense\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "\n",
        "# Load your dataframe (example)\n",
        "df = pd.read_csv('image_pairs.csv')  # Assumes 'image_1' and 'image_2' columns with paths\n",
        "\n",
        "# Image dimensions (same for both images)\n",
        "IMAGE_SIZE = (224, 224)  # Modify as per your model's input size\n",
        "\n",
        "# Helper function to load and preprocess images\n",
        "def preprocess_image(img_path, target_size=IMAGE_SIZE):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = tf.keras.applications.resnet50.preprocess_input(img_array)  # If using ResNet\n",
        "    return img_array\n",
        "\n",
        "# Function to create the Siamese Network\n",
        "def build_siamese_model(input_shape=(224, 224, 3)):\n",
        "    # Base model using ResNet50 (you can use any model)\n",
        "    base_model = ResNet50(include_top=False, input_shape=input_shape)\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    # Adding custom layers on top of base model\n",
        "    flatten = Flatten()(base_model.output)\n",
        "    dense = Dense(128, activation=\"relu\")(flatten)\n",
        "    output = Dense(64, activation=\"sigmoid\")(dense)\n",
        "\n",
        "    # Create the model using the base model and the custom layers\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Lambda layer for computing Euclidean distance\n",
        "def euclidean_distance(vectors):\n",
        "    (feat1, feat2) = vectors\n",
        "    sum_square = tf.reduce_sum(tf.square(feat1 - feat2), axis=1, keepdims=True)\n",
        "    return tf.sqrt(tf.maximum(sum_square, 1e-6))\n",
        "\n",
        "# Contrastive loss function (if using it for training)\n",
        "def contrastive_loss(y_true, y_pred, margin=1):\n",
        "    square_pred = tf.square(y_pred)\n",
        "    margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
        "    return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
        "\n",
        "# Data generator that yields image pairs and labels\n",
        "def data_generator(df, batch_size=32):\n",
        "    while True:\n",
        "        for start in range(0, len(df), batch_size):\n",
        "            batch = df[start:start + batch_size]\n",
        "            img1 = np.array([preprocess_image(img) for img in batch['image_1']])\n",
        "            img2 = np.array([preprocess_image(img) for img in batch['image_2']])\n",
        "            labels = np.array(batch['label'])  # Assuming 'label' column in the DataFrame\n",
        "            yield [img1, img2], labels\n",
        "\n",
        "# Build the model\n",
        "input_shape = (224, 224, 3)\n",
        "siamese_network = build_siamese_model(input_shape)\n",
        "\n",
        "# Create the model with the distance layer\n",
        "input_1 = Input(input_shape)\n",
        "input_2 = Input(input_shape)\n",
        "\n",
        "# Create the shared model\n",
        "shared_model = siamese_network\n",
        "\n",
        "# Get the embeddings\n",
        "output_1 = shared_model(input_1)\n",
        "output_2 = shared_model(input_2)\n",
        "\n",
        "# Calculate the Euclidean distance\n",
        "distance = Lambda(euclidean_distance)([output_1, output_2])\n",
        "\n",
        "# Define the full Siamese model\n",
        "siamese_model = Model(inputs=[input_1, input_2], outputs=distance)\n",
        "\n",
        "# Compile the model with contrastive loss and an optimizer\n",
        "siamese_model.compile(loss=contrastive_loss, optimizer=Adam(learning_rate=0.0001))\n",
        "\n",
        "# Assuming you have a CSV like this:\n",
        "# image_1          | image_2          | label\n",
        "# /path/to/img1    | /path/to/img2    | 0\n",
        "# /path/to/img3    | /path/to/img4    | 1\n",
        "# where 'label' = 0 means the images are not similar, 'label' = 1 means they are similar\n",
        "\n",
        "# Train the model using the data generator\n",
        "siamese_model.fit(data_generator(df), epochs=10, steps_per_epoch=len(df) // 32)\n"
      ],
      "metadata": {
        "id": "11XIXZgW8N_t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}